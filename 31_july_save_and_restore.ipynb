{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31 july save and restore.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQCeZwjHJhKd",
        "colab_type": "code",
        "outputId": "387516d5-7099-46f1-e8d3-6fb06098f4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!pip install h5py pyyaml\n",
        "!pip install tf_nightly"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.4)\n",
            "Requirement already satisfied: tf_nightly in /usr/local/lib/python3.6/dist-packages (1.15.0.dev20190730)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.16.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (3.7.1)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.14.0.dev2019073001)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.0.8)\n",
            "Requirement already satisfied: tb-nightly<1.16.0a0,>=1.15.0a0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.15.0a20190730)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf_nightly) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf_nightly) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf_nightly) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf_nightly) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlk7ORhCKSRU",
        "colab_type": "code",
        "outputId": "6cf838fe-e272-4e91-e613-a484a1bc47fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0-dev20190730'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT60FzvRZT5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZN0bhRvYYRr",
        "colab_type": "code",
        "outputId": "e24e03b1-cd63-4973-e0eb-793b562fc2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Returns a short sequential model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation=tf.keras.activations.relu, input_shape=(784,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 09:38:55.284304 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0731 09:38:55.285528 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0731 09:38:55.288083 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0731 09:38:55.289984 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0731 09:38:55.293409 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0731 09:38:55.296646 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0731 09:38:55.299530 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0731 09:38:55.302395 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0731 09:38:55.305376 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0731 09:38:55.309051 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0731 09:38:55.310179 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0731 09:38:55.312124 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0731 09:38:55.313253 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0731 09:38:55.315410 140593696061312 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuB5r927YZhA",
        "colab_type": "code",
        "outputId": "3c054143-c6af-4aa8-ca4d-b1086629f6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels,  epochs = 10,\n",
        "          validation_data = (test_images,test_labels),\n",
        "          callbacks = [cp_callback])  # pass callback to training\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 09:39:24.741672 140593696061312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:468: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Apply a constraint manually following the optimizer update step.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            " 832/1000 [=======================>......] - ETA: 0s - loss: 1.2477 - acc: 0.6466\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 1s 623us/sample - loss: 1.1490 - acc: 0.6730 - val_loss: 0.7145 - val_acc: 0.7810\n",
            "Epoch 2/10\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.4191 - acc: 0.8839\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 285us/sample - loss: 0.4112 - acc: 0.8830 - val_loss: 0.5809 - val_acc: 0.8120\n",
            "Epoch 3/10\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.2750 - acc: 0.9310\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 276us/sample - loss: 0.2830 - acc: 0.9270 - val_loss: 0.4432 - val_acc: 0.8620\n",
            "Epoch 4/10\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.2018 - acc: 0.9554\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 292us/sample - loss: 0.2052 - acc: 0.9520 - val_loss: 0.4300 - val_acc: 0.8600\n",
            "Epoch 5/10\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.1483 - acc: 0.9740\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 292us/sample - loss: 0.1456 - acc: 0.9750 - val_loss: 0.4660 - val_acc: 0.8470\n",
            "Epoch 6/10\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.1193 - acc: 0.9802\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 293us/sample - loss: 0.1187 - acc: 0.9800 - val_loss: 0.4134 - val_acc: 0.8660\n",
            "Epoch 7/10\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0744 - acc: 0.9903\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 291us/sample - loss: 0.0803 - acc: 0.9890 - val_loss: 0.4002 - val_acc: 0.8710\n",
            "Epoch 8/10\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0624 - acc: 0.9922\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 284us/sample - loss: 0.0656 - acc: 0.9900 - val_loss: 0.4193 - val_acc: 0.8630\n",
            "Epoch 9/10\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0463 - acc: 0.9989\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 268us/sample - loss: 0.0498 - acc: 0.9990 - val_loss: 0.4285 - val_acc: 0.8570\n",
            "Epoch 10/10\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0407 - acc: 0.9989\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 276us/sample - loss: 0.0407 - acc: 0.9990 - val_loss: 0.4231 - val_acc: 0.8580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde379c1a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sUQ25czYe7N",
        "colab_type": "code",
        "outputId": "9cffe1c1-eed0-49d7-98ec-d56ff26464f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     cp.ckpt.data-00001-of-00002\n",
            "cp.ckpt.data-00000-of-00002  cp.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdOfnNbCYkKd",
        "colab_type": "code",
        "outputId": "6a42cb01-a979-479b-929c-f835a501dec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 132us/sample - loss: 2.3916 - acc: 0.0780\n",
            "Untrained model, accuracy:  7.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqsmsWsZYnUz",
        "colab_type": "code",
        "outputId": "b814a6ef-7078-419d-b7a0-7cc006a65ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "loss,acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 76us/sample - loss: 0.4231 - acc: 0.8580\n",
            "Restored model, accuracy: 85.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU246wAcbZd6",
        "colab_type": "code",
        "outputId": "745295f6-af37-4a1f-df9d-fb5a3601f54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 273us/sample - loss: 1.1366 - acc: 0.6860\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 179us/sample - loss: 0.4271 - acc: 0.8820\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 179us/sample - loss: 0.2907 - acc: 0.9180\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 178us/sample - loss: 0.2288 - acc: 0.9450\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 173us/sample - loss: 0.1623 - acc: 0.9610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amwz9f0xdyw3",
        "colab_type": "code",
        "outputId": "62a7c0f1-51b5-4d6a-c4d0-066b9cd64338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "new_model = keras.models.load_model('my_model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 09:58:12.904221 140593696061312 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0731 09:58:12.907056 140593696061312 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZyXGuOhdzb-",
        "colab_type": "code",
        "outputId": "1bb9f329-0788-4be7-ca0e-e13a7455cd19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 149us/sample - loss: 0.4312 - acc: 0.8570\n",
            "Restored model, accuracy: 85.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lPTEFehd_hc",
        "colab_type": "code",
        "outputId": "445cce82-b9c6-48d2-dae6-c523f62fa7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 09:59:13.549267 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0731 09:59:13.550845 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0731 09:59:13.552720 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0731 09:59:13.557319 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0731 09:59:13.558132 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0731 09:59:13.559848 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0731 09:59:13.561800 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0731 09:59:13.563588 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0731 09:59:13.564980 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0731 09:59:13.566109 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0731 09:59:13.567425 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0731 09:59:13.568994 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0731 09:59:13.570888 140593696061312 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0731 09:59:13.572241 140593696061312 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 277us/sample - loss: 1.1125 - acc: 0.6950\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 161us/sample - loss: 0.4393 - acc: 0.8730\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 181us/sample - loss: 0.2918 - acc: 0.9220\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 172us/sample - loss: 0.2093 - acc: 0.9540\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 183us/sample - loss: 0.1486 - acc: 0.9640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde381f0470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wpexA3jeCHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}